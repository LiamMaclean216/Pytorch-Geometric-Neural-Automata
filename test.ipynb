{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'update_rule' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lmacl\\Google Drive\\GitHub\\Pytorch-Geometric-Neural-Automata\\test.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W0sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m n_outputs \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W0sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# update_rule = UpdateRule(\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W0sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m#     n_inputs, \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W0sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m#     n_outputs,\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W0sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m#     hidden_dim,\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W0sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m#     4\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W0sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W0sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m update_rule\u001b[39m.\u001b[39mbuild_graph(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W0sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     height,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W0sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     width\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W0sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W0sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# cuda_device = torch.device(\"cuda:0\" if torch.cuda.is_available else \"cpu\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W0sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m cuda_device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'update_rule' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# conda install pytorch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0 -c pytorch -y & conda install pyg -c pyg -y & conda install -c anaconda networkx -y & conda install -c conda-forge matplotlib -y\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric.utils as utils\n",
    "from utils import *\n",
    "from model import UpdateRule\n",
    "\n",
    "\n",
    "height = 1\n",
    "width = 3\n",
    "hidden_dim = 8\n",
    "\n",
    "n_inputs = 2\n",
    "n_outputs = 3\n",
    "\n",
    "\n",
    "update_rule = UpdateRule(\n",
    "    n_inputs, \n",
    "    n_outputs,\n",
    "    hidden_dim,\n",
    "    4\n",
    ")\n",
    "update_rule.build_graph(\n",
    "    height,\n",
    "    width\n",
    ")\n",
    "\n",
    "\n",
    "# cuda_device = torch.device(\"cuda:0\" if torch.cuda.is_available else \"cpu\")\n",
    "cuda_device = torch.device(\"cpu\")\n",
    "\n",
    "update_rule = update_rule.to(cuda_device)\n",
    "\n",
    "update_rule.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 0 | Loss 2.0328893661499023 out: [0. 1. 0.] | Correct:  [0. 1. 0.]         \n",
      " Epoch 200 | Loss 1.6995563507080078 out: [0. 0. 1.] | Correct:  [0. 0. 1.]         \n",
      " Epoch 300 | Loss 1.6995595693588257 out: [0. 1. 0.] | Correct:  [0. 1. 0.]         "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lmacl\\Google Drive\\GitHub\\Pytorch-Geometric-Neural-Automata\\test.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m x \u001b[39m=\u001b[39m update_rule\u001b[39m.\u001b[39minitial_state(height, width)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# for idx, (problem_data_x, problem_data_y) in enumerate(meta_set.get_set(set_idx)):\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W1sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m x, batch_loss, network_output, correct \u001b[39m=\u001b[39m update_rule(x, n_steps, meta_set\u001b[39m.\u001b[39mget_set(set_idx))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W1sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_loss\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W1sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# network_output = update_rule.get_output(x)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W1sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# loss = F.mse_loss(problem_data_y.float().squeeze(0), network_output)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W1sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# loss += F.mse_loss(problem_data_y.float().squeeze(0), network_output)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W1sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W1sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m#cross entropy loss\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W1sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# loss += F.binary_cross_entropy_with_logits(network_output, problem_data_y.float().squeeze(0))\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lmacl\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\lmacl\\Google Drive\\GitHub\\Pytorch-Geometric-Neural-Automata\\model.py:117\u001b[0m, in \u001b[0;36mUpdateRule.forward\u001b[1;34m(self, x, n_steps, data, plug_output_data)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[39m# x = x.unsqueeze(-1).repeat(1, 1, n_steps)\u001b[39;00m\n\u001b[0;32m    116\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_steps):\n\u001b[1;32m--> 117\u001b[0m         x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep(x, problem_data_x\u001b[39m.\u001b[39;49mfloat(), output_data)\n\u001b[0;32m    120\u001b[0m     \u001b[39m# break\u001b[39;00m\n\u001b[0;32m    121\u001b[0m network_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_output(x)\n",
      "File \u001b[1;32mc:\\Users\\lmacl\\Google Drive\\GitHub\\Pytorch-Geometric-Neural-Automata\\model.py:149\u001b[0m, in \u001b[0;36mUpdateRule.step\u001b[1;34m(self, x, input_data, output_data)\u001b[0m\n\u001b[0;32m    146\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m    147\u001b[0m     \u001b[39m# x = x + inner_skip\u001b[39;00m\n\u001b[1;32m--> 149\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv_out(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49medge_index)\n\u001b[0;32m    151\u001b[0m x \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m skip\n\u001b[0;32m    154\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\lmacl\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\lmacl\\miniconda3\\lib\\site-packages\\torch_geometric\\nn\\conv\\gat_conv.py:229\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[1;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[0;32m    226\u001b[0m     num_nodes \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(size) \u001b[39mif\u001b[39;00m size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m num_nodes\n\u001b[0;32m    227\u001b[0m     edge_index, edge_attr \u001b[39m=\u001b[39m remove_self_loops(\n\u001b[0;32m    228\u001b[0m         edge_index, edge_attr)\n\u001b[1;32m--> 229\u001b[0m     edge_index, edge_attr \u001b[39m=\u001b[39m add_self_loops(\n\u001b[0;32m    230\u001b[0m         edge_index, edge_attr, fill_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfill_value,\n\u001b[0;32m    231\u001b[0m         num_nodes\u001b[39m=\u001b[39;49mnum_nodes)\n\u001b[0;32m    232\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(edge_index, SparseTensor):\n\u001b[0;32m    233\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_dim \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\lmacl\\miniconda3\\lib\\site-packages\\torch_geometric\\utils\\loop.py:121\u001b[0m, in \u001b[0;36madd_self_loops\u001b[1;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[0;32m    118\u001b[0m N \u001b[39m=\u001b[39m maybe_num_nodes(edge_index, num_nodes)\n\u001b[0;32m    120\u001b[0m loop_index \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m, N, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39medge_index\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m--> 121\u001b[0m loop_index \u001b[39m=\u001b[39m loop_index\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mrepeat(\u001b[39m2\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n\u001b[0;32m    123\u001b[0m \u001b[39mif\u001b[39;00m edge_attr \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[39mif\u001b[39;00m fill_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datasets import *\n",
    "import copy\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=1, suppress=True)\n",
    "\n",
    "\n",
    "# dataset_loader = DataLoader(TranslateDataset(), batch_size=1, shuffle=True)\n",
    "\n",
    "meta_set = MetaDataset()\n",
    "\n",
    "optimizer = torch.optim.Adam(update_rule.parameters(), lr=0.001)\n",
    "\n",
    "best_loss = 10000\n",
    "best_model = None\n",
    "\n",
    "n_steps = 2\n",
    "batch_size = 5\n",
    "for epoch in range(10000):\n",
    "    loss = 0\n",
    "    for _ in range(batch_size):\n",
    "        for set_idx in meta_set.iterate():\n",
    "            update_rule.reset() \n",
    "            x = update_rule.initial_state(height, width)\n",
    "            # for idx, (problem_data_x, problem_data_y) in enumerate(meta_set.get_set(set_idx)):\n",
    "                \n",
    "        \n",
    "            x, batch_loss, network_output, correct = update_rule(x, n_steps, meta_set.get_set(set_idx))\n",
    "            loss += batch_loss\n",
    "                \n",
    "            # network_output = update_rule.get_output(x)\n",
    "            # loss = F.mse_loss(problem_data_y.float().squeeze(0), network_output)\n",
    "            # loss += F.mse_loss(problem_data_y.float().squeeze(0), network_output)\n",
    "            \n",
    "            #cross entropy loss\n",
    "            # loss += F.binary_cross_entropy_with_logits(network_output, problem_data_y.float().squeeze(0))\n",
    "           \n",
    "            \n",
    "    if loss < best_loss:\n",
    "        # best_model = copy.deepcopy(update_rule)\n",
    "        best_loss = loss\n",
    "     \n",
    "    loss /= batch_size   \n",
    "    loss.backward()\n",
    "    \n",
    "    nn.utils.clip_grad_norm_(update_rule.parameters(), 1)\n",
    "    optimizer.step()  \n",
    "    optimizer.zero_grad()  \n",
    "        \n",
    "    print(f\"\"\"\\r \n",
    "          Epoch {epoch * batch_size} |\n",
    "          Loss {loss:.6} |\n",
    "          Network out: {network_output} |\n",
    "          Correct:  {correct}\n",
    "        \"\"\".replace(\"\\n\", \" \").replace(\"          \", \"\"), end=\"\")\n",
    "    \n",
    "    print(f\"\\r Epoch {epoch * batch_size} | Loss {loss}\", end=\"\")\n",
    "    if epoch % (200 // batch_size) == 0:\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lmacl\\Google Drive\\GitHub\\Pytorch-Geometric-Neural-Automata\\test.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m np\u001b[39m.\u001b[39mset_printoptions(precision\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m run_rule(torch\u001b[39m.\u001b[39mtensor([[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m]]), update_rule)\n",
      "File \u001b[1;32mc:\\Users\\lmacl\\Google Drive\\GitHub\\Pytorch-Geometric-Neural-Automata\\utils.py:79\u001b[0m, in \u001b[0;36mrun_rule\u001b[1;34m(data_x, update_rule, n_steps)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[39m# edge_index = data.edge_index.long().clone()\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_steps):\n\u001b[1;32m---> 79\u001b[0m     x \u001b[39m=\u001b[39m update_rule(x, data_x\u001b[39m.\u001b[39;49mfloat())\n\u001b[0;32m     81\u001b[0m     network_output \u001b[39m=\u001b[39m update_rule\u001b[39m.\u001b[39mget_output(x)\u001b[39m.\u001b[39mdetach()\n\u001b[0;32m     82\u001b[0m     \u001b[39mprint\u001b[39m(network_output)\n",
      "File \u001b[1;32mc:\\Users\\lmacl\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'data'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "run_rule(torch.tensor([[0,0,0,1]]), update_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_rule_meta(update_rule, training, test, n_steps):\n",
    "    x = update_rule.initial_state(height, width)\n",
    "    for (problem_x, problem_y) in training:\n",
    "        print(problem_x)\n",
    "        for _ in range(n_steps):\n",
    "            x = update_rule(x, problem_x.float(), problem_y.float())\n",
    "            \n",
    "            \n",
    "    for _ in range(n_steps):\n",
    "        x = update_rule(x, test.float())\n",
    "        \n",
    "    network_output = update_rule.get_output(x).detach()\n",
    "    return network_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_rule_meta(update_rule, torch.tensor([\n",
    "#     ([1,0,0,0], [0,1,0,0]),\n",
    "#     ([0,1,0,0], [0,0,1,0]),\n",
    "#     ([0,0,1,0], [0,0,0,1]),\n",
    "#     ]), torch.tensor([0,1,0,0]), 8)\n",
    "\n",
    "# run_rule_meta(best_model, torch.tensor([\n",
    "#     ([1,0,0,0,0,0,0], [0,1,0,0,0,0,0]),\n",
    "#     ([0,1,0,0,0,0,0], [0,0,1,0,0,0,0]),\n",
    "#     # ([0,0,1,0,0,0,0], [0,1,0,0,0,0,0]),\n",
    "#     ([0,0,0,1,0,0,0], [0,0,0,0,1,0,0]),\n",
    "#     ([0,0,0,0,1,0,0], [0,0,0,0,0,1,0]),\n",
    "#     ([0,0,0,0,0,1,0], [0,0,0,0,0,0,1]),\n",
    "#     ([0,0,0,0,0,0,1], [1,0,0,0,0,0,0]),\n",
    "#     ]), torch.tensor([0,0,1,0,0,0,0]), n_steps)\n",
    "\n",
    "run_rule_meta(best_model, torch.tensor([\n",
    "    ([1,0,0,0,0,0,0], [0,0,0,0,0,0,1]),\n",
    "    ([0,1,0,0,0,0,0], [1,0,0,0,0,0,0]),\n",
    "    # ([0,0,1,0,0,0,0], [0,1,0,0,0,0,0]),\n",
    "    ([0,0,0,1,0,0,0], [0,0,1,0,0,0,0]),\n",
    "    ([0,0,0,0,1,0,0], [0,0,0,1,0,0,0]),\n",
    "    ([0,0,0,0,0,1,0], [0,0,0,0,1,0,0]),\n",
    "    ([0,0,0,0,0,0,1], [0,0,0,0,0,1,0]),\n",
    "    ]), torch.tensor([0,0,1,0,0,0,0]), n_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_rule.initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.rand([1,5])\n",
    "#repeat on first dimension 3 times without using .repeat\n",
    "test = test.expand(3, -1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_set = MetaDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.stack(list(meta_set.get_set(0))[0], 1))\n",
    "print(torch.stack(list(meta_set.get_set(0))[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.dataset import METRLADatasetLoader\n",
    "from torch_geometric_temporal.signal import StaticGraphTemporalSignal\n",
    "\n",
    "loader = METRLADatasetLoader()\n",
    "dataset = loader.get_dataset(num_timesteps_in=12, num_timesteps_out=5)\n",
    "\n",
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)\n",
    "\n",
    "for snapshot in train_dataset:\n",
    "    print(snapshot.x.shape)\n",
    "    print(snapshot.y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8645a3289b338b219b448912b5fab165e90ac259118b71d23942463e3b992b2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
