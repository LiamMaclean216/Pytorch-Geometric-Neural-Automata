{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lmacl\\miniconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch_geometric.utils as utils\n",
    "\n",
    "\n",
    "height = 2\n",
    "width = 2\n",
    "hidden_dim = 8\n",
    "\n",
    "n_inputs = 2\n",
    "n_outputs = 2\n",
    "\n",
    "def build_edges(n_inputs: int, n_outputs: int, height: int, width: int):\n",
    "    \"\"\"\n",
    "    Builds edges like 2d_grid_graph\n",
    "    \"\"\"\n",
    "    #hidden neurons\n",
    "    edge_list = list(nx.grid_2d_graph(height, width).edges())\n",
    "    node_list = list(nx.grid_2d_graph(height, width).nodes())\n",
    "\n",
    "    #replace each element of edge_list with its index in node_list\n",
    "    for i in range(len(edge_list)):\n",
    "        edge_list[i] = (node_list.index(edge_list[i][0]), node_list.index(edge_list[i][1]))\n",
    "        \n",
    "    edges = torch.tensor(edge_list)\n",
    "    \n",
    "    #input neurons\n",
    "    input_edges = torch.tensor([\n",
    "        [\n",
    "            [x, (height*width) + y] for x in range(width)\n",
    "        ] for y in range(n_inputs)\n",
    "    ]).view(-1, 2)\n",
    "\n",
    "    #output neurons\n",
    "    output_edges = torch.tensor([\n",
    "        [\n",
    "            [(height*width)-(x+1), (height*width) + y+n_inputs] for x in range(width)\n",
    "        ] for y in range(n_outputs)\n",
    "    ]).view(-1, 2)\n",
    "\n",
    "    #merge edges and input_edges\n",
    "    edges = torch.cat((edges, input_edges, output_edges), dim=0).transpose(0,1)\n",
    "    return edges\n",
    "\n",
    "\n",
    "\n",
    "edges = build_edges(n_inputs, n_outputs, height, width)\n",
    "edges =  torch.stack((torch.concat((edges[0], edges[1]), 0), torch.concat((edges[1], edges[0]), 0)), 0)\n",
    "\n",
    "n_nodes = height*width + n_inputs + n_outputs\n",
    "\n",
    "type_dict = {\"hidden\": [1, 0, 0], \"input\": [0, 1, 0], \"output\": [0, 0, 1]}\n",
    "total_hidden_dim = hidden_dim + len(type_dict[\"hidden\"]) #hidden data + type\n",
    "\n",
    "# def set_node_state(input_data: torch.Tensor, output_data: torch.Tensor):\n",
    "x = torch.zeros(n_nodes, total_hidden_dim)\n",
    "\n",
    "n_hidden_nodes = height*width\n",
    "x[:n_hidden_nodes] = torch.concat((torch.ones(hidden_dim)*(-1), torch.tensor(type_dict[\"hidden\"])))\n",
    "x[n_hidden_nodes:n_hidden_nodes+n_inputs] = torch.concat((torch.ones(hidden_dim)*(-1), torch.tensor(type_dict[\"input\"])))\n",
    "x[n_hidden_nodes+n_inputs:n_hidden_nodes+n_inputs+n_outputs] = torch.concat((torch.ones(hidden_dim)*(-1), torch.tensor(type_dict[\"output\"])))\n",
    "\n",
    "\n",
    "\n",
    "data = Data(edge_index=edges, x=x)\n",
    "\n",
    "graph = utils.to_networkx(data, to_undirected=True, remove_self_loops = True)\n",
    "nx.draw(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pytorch geometric graph classification\n",
    "from torch_geometric.nn import GCNConv, Sequential\n",
    "from torch.nn import ReLU, LeakyReLU\n",
    "\n",
    "\n",
    "class UpdateRule(torch.nn.Module):\n",
    "    def __init__(self, width = 4):\n",
    "        super(UpdateRule, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "\n",
    "        self.relu = nn.LeakyReLU(0.1, inplace=True)\n",
    "        self.input_vectorizer = nn.Linear(n_inputs, total_hidden_dim, bias=True)\n",
    "        \n",
    "        # Vectorizes training targets\n",
    "        self.reverse_output_vectorizer = nn.Linear(n_outputs, hidden_dim)\n",
    "        \n",
    "        self.output_vectorizer = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "        self.conv1 = GCNConv(total_hidden_dim+n_nodes, width)\n",
    "        \n",
    "        n_hidden_rule_layers = 2\n",
    "        self.hidden_rule_layers = Sequential('x, edge_index', \n",
    "                                             [x for i in range(n_hidden_rule_layers) for x in \n",
    "                                              [(GCNConv(width, width), 'x, edge_index -> x'), LeakyReLU(0.1, True)]])\n",
    "        \n",
    "        # self.conv2 = GCNConv(width, width)\n",
    "        self.conv_out = GCNConv(width, hidden_dim)\n",
    "        \n",
    "        self.reset()\n",
    "\n",
    "    def get_indices(self, x, type: str):\n",
    "        return torch.argwhere((x[:,hidden_dim:] == torch.tensor(type_dict[type])).all(1)).squeeze(-1)\n",
    "    \n",
    "    def forward(self, x, edge_index, input_data):\n",
    "        types = get_type(x.clone(), hidden_dim=hidden_dim)\n",
    "        \n",
    "        \n",
    "        #vectorize input\n",
    "        mask = torch.zeros(x.shape)\n",
    "        mask[self.get_indices(x, \"input\"), :hidden_dim] = 1\n",
    "        # print(x)\n",
    "        # x = ((self.input_vectorizer(input_data)) * mask)\n",
    "        x = x+((self.input_vectorizer(input_data)-x) * mask)\n",
    "        \n",
    "        #each output needs a unique identifier\n",
    "        \n",
    "        # input_indices, output_indices, hidden_indices = self.get_indices(x, \"input\"), self.get_indices(x, \"output\"), self.get_indices(x, \"hidden\")\n",
    "        # identifiers = F.one_hot(torch.arange(0, input_indices.shape[0] + output_indices.shape[0]))\n",
    "        # identifiers = torch.concat((torch.zeros(hidden_indices.shape[0], identifiers.shape[0]), identifiers), 0)\n",
    "        # identifiers[0][0] = 1\n",
    "        # print(identifiers)\n",
    "        \n",
    "        identifiers = F.one_hot(torch.arange(0, n_nodes))\n",
    "        # identifiers[self.get_indices(x, \"hidden\")] *= 0\n",
    "        # identifiers[0] *= 0\n",
    "        \n",
    "        x = torch.concat((identifiers, x), -1)\n",
    "        # print(x)\n",
    "        # print(x)\n",
    "        # x = torch.concat((x, F.one_hot(torch.arange(0, 5))), -1)\n",
    "        \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.relu(x)\n",
    "        # x = x.relu()\n",
    "        \n",
    "        x = self.hidden_rule_layers(x, edge_index)\n",
    "        \n",
    "        # x = self.conv2(x, edge_index)\n",
    "        \n",
    "        x = self.conv_out(x, edge_index)\n",
    "        \n",
    "        # x = x.tanh()\n",
    "        \n",
    "        x = torch.cat([x, types], dim=-1)\n",
    "        return x\n",
    "    \n",
    "    def print_grad(self):\n",
    "        for idx,i in enumerate([self.input_vectorizer, self.output_vectorizer]):\n",
    "            print(idx)\n",
    "            print(i.weight.grad)\n",
    "            print()\n",
    "            \n",
    "        for idx,i in enumerate([self.conv1]):\n",
    "            print(idx)\n",
    "            print(i.lin.weight.grad)\n",
    "            print()\n",
    "        \n",
    "        print(\"hiddens:\")\n",
    "        for i in self.hidden_rule_layers.children():\n",
    "            try:\n",
    "                print(i.lin.weight.grad)\n",
    "                print()\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    def reset_outputs(self, x, output_data):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Network state before rule application\n",
    "            output_data: Training targets\n",
    "        \"\"\"\n",
    "        if self.vectorized_output is None:\n",
    "            self.vectorized_output = self.reverse_output_vectorizer(output_data)\n",
    "        \n",
    "        output_indices = torch.argwhere((x[:,hidden_dim:] == torch.tensor(type_dict[\"output\"])).all(1)).squeeze(-1)\n",
    "        x[output_indices, :hidden_dim] = self.vectorized_input\n",
    "        return x\n",
    "    \n",
    "    def get_output(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Network state after rule application\n",
    "        \"\"\"\n",
    "        output_indices = torch.argwhere((x[:,hidden_dim:] == torch.tensor(type_dict[\"output\"])).all(1)).squeeze(-1)\n",
    "        return self.output_vectorizer(x[output_indices, :hidden_dim]).sigmoid().squeeze(-1)\n",
    "        \n",
    "    \n",
    "    def reset(self):\n",
    "        self.vectorized_input = None\n",
    "        self.vectorized_output = None\n",
    "        \n",
    "            \n",
    "update_rule = UpdateRule()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "/* Put everything inside the global mpl namespace */\n/* global mpl */\nwindow.mpl = {};\n\nmpl.get_websocket_type = function () {\n    if (typeof WebSocket !== 'undefined') {\n        return WebSocket;\n    } else if (typeof MozWebSocket !== 'undefined') {\n        return MozWebSocket;\n    } else {\n        alert(\n            'Your browser does not have WebSocket support. ' +\n                'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n                'Firefox 4 and 5 are also supported but you ' +\n                'have to enable WebSockets in about:config.'\n        );\n    }\n};\n\nmpl.figure = function (figure_id, websocket, ondownload, parent_element) {\n    this.id = figure_id;\n\n    this.ws = websocket;\n\n    this.supports_binary = this.ws.binaryType !== undefined;\n\n    if (!this.supports_binary) {\n        var warnings = document.getElementById('mpl-warnings');\n        if (warnings) {\n            warnings.style.display = 'block';\n            warnings.textContent =\n                'This browser does not support binary websocket messages. ' +\n                'Performance may be slow.';\n        }\n    }\n\n    this.imageObj = new Image();\n\n    this.context = undefined;\n    this.message = undefined;\n    this.canvas = undefined;\n    this.rubberband_canvas = undefined;\n    this.rubberband_context = undefined;\n    this.format_dropdown = undefined;\n\n    this.image_mode = 'full';\n\n    this.root = document.createElement('div');\n    this.root.setAttribute('style', 'display: inline-block');\n    this._root_extra_style(this.root);\n\n    parent_element.appendChild(this.root);\n\n    this._init_header(this);\n    this._init_canvas(this);\n    this._init_toolbar(this);\n\n    var fig = this;\n\n    this.waiting = false;\n\n    this.ws.onopen = function () {\n        fig.send_message('supports_binary', { value: fig.supports_binary });\n        fig.send_message('send_image_mode', {});\n        if (fig.ratio !== 1) {\n            fig.send_message('set_device_pixel_ratio', {\n                device_pixel_ratio: fig.ratio,\n            });\n        }\n        fig.send_message('refresh', {});\n    };\n\n    this.imageObj.onload = function () {\n        if (fig.image_mode === 'full') {\n            // Full images could contain transparency (where diff images\n            // almost always do), so we need to clear the canvas so that\n            // there is no ghosting.\n            fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n        }\n        fig.context.drawImage(fig.imageObj, 0, 0);\n    };\n\n    this.imageObj.onunload = function () {\n        fig.ws.close();\n    };\n\n    this.ws.onmessage = this._make_on_message_function(this);\n\n    this.ondownload = ondownload;\n};\n\nmpl.figure.prototype._init_header = function () {\n    var titlebar = document.createElement('div');\n    titlebar.classList =\n        'ui-dialog-titlebar ui-widget-header ui-corner-all ui-helper-clearfix';\n    var titletext = document.createElement('div');\n    titletext.classList = 'ui-dialog-title';\n    titletext.setAttribute(\n        'style',\n        'width: 100%; text-align: center; padding: 3px;'\n    );\n    titlebar.appendChild(titletext);\n    this.root.appendChild(titlebar);\n    this.header = titletext;\n};\n\nmpl.figure.prototype._canvas_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._root_extra_style = function (_canvas_div) {};\n\nmpl.figure.prototype._init_canvas = function () {\n    var fig = this;\n\n    var canvas_div = (this.canvas_div = document.createElement('div'));\n    canvas_div.setAttribute(\n        'style',\n        'border: 1px solid #ddd;' +\n            'box-sizing: content-box;' +\n            'clear: both;' +\n            'min-height: 1px;' +\n            'min-width: 1px;' +\n            'outline: 0;' +\n            'overflow: hidden;' +\n            'position: relative;' +\n            'resize: both;'\n    );\n\n    function on_keyboard_event_closure(name) {\n        return function (event) {\n            return fig.key_event(event, name);\n        };\n    }\n\n    canvas_div.addEventListener(\n        'keydown',\n        on_keyboard_event_closure('key_press')\n    );\n    canvas_div.addEventListener(\n        'keyup',\n        on_keyboard_event_closure('key_release')\n    );\n\n    this._canvas_extra_style(canvas_div);\n    this.root.appendChild(canvas_div);\n\n    var canvas = (this.canvas = document.createElement('canvas'));\n    canvas.classList.add('mpl-canvas');\n    canvas.setAttribute('style', 'box-sizing: content-box;');\n\n    this.context = canvas.getContext('2d');\n\n    var backingStore =\n        this.context.backingStorePixelRatio ||\n        this.context.webkitBackingStorePixelRatio ||\n        this.context.mozBackingStorePixelRatio ||\n        this.context.msBackingStorePixelRatio ||\n        this.context.oBackingStorePixelRatio ||\n        this.context.backingStorePixelRatio ||\n        1;\n\n    this.ratio = (window.devicePixelRatio || 1) / backingStore;\n\n    var rubberband_canvas = (this.rubberband_canvas = document.createElement(\n        'canvas'\n    ));\n    rubberband_canvas.setAttribute(\n        'style',\n        'box-sizing: content-box; position: absolute; left: 0; top: 0; z-index: 1;'\n    );\n\n    // Apply a ponyfill if ResizeObserver is not implemented by browser.\n    if (this.ResizeObserver === undefined) {\n        if (window.ResizeObserver !== undefined) {\n            this.ResizeObserver = window.ResizeObserver;\n        } else {\n            var obs = _JSXTOOLS_RESIZE_OBSERVER({});\n            this.ResizeObserver = obs.ResizeObserver;\n        }\n    }\n\n    this.resizeObserverInstance = new this.ResizeObserver(function (entries) {\n        var nentries = entries.length;\n        for (var i = 0; i < nentries; i++) {\n            var entry = entries[i];\n            var width, height;\n            if (entry.contentBoxSize) {\n                if (entry.contentBoxSize instanceof Array) {\n                    // Chrome 84 implements new version of spec.\n                    width = entry.contentBoxSize[0].inlineSize;\n                    height = entry.contentBoxSize[0].blockSize;\n                } else {\n                    // Firefox implements old version of spec.\n                    width = entry.contentBoxSize.inlineSize;\n                    height = entry.contentBoxSize.blockSize;\n                }\n            } else {\n                // Chrome <84 implements even older version of spec.\n                width = entry.contentRect.width;\n                height = entry.contentRect.height;\n            }\n\n            // Keep the size of the canvas and rubber band canvas in sync with\n            // the canvas container.\n            if (entry.devicePixelContentBoxSize) {\n                // Chrome 84 implements new version of spec.\n                canvas.setAttribute(\n                    'width',\n                    entry.devicePixelContentBoxSize[0].inlineSize\n                );\n                canvas.setAttribute(\n                    'height',\n                    entry.devicePixelContentBoxSize[0].blockSize\n                );\n            } else {\n                canvas.setAttribute('width', width * fig.ratio);\n                canvas.setAttribute('height', height * fig.ratio);\n            }\n            canvas.setAttribute(\n                'style',\n                'width: ' + width + 'px; height: ' + height + 'px;'\n            );\n\n            rubberband_canvas.setAttribute('width', width);\n            rubberband_canvas.setAttribute('height', height);\n\n            // And update the size in Python. We ignore the initial 0/0 size\n            // that occurs as the element is placed into the DOM, which should\n            // otherwise not happen due to the minimum size styling.\n            if (fig.ws.readyState == 1 && width != 0 && height != 0) {\n                fig.request_resize(width, height);\n            }\n        }\n    });\n    this.resizeObserverInstance.observe(canvas_div);\n\n    function on_mouse_event_closure(name) {\n        return function (event) {\n            return fig.mouse_event(event, name);\n        };\n    }\n\n    rubberband_canvas.addEventListener(\n        'mousedown',\n        on_mouse_event_closure('button_press')\n    );\n    rubberband_canvas.addEventListener(\n        'mouseup',\n        on_mouse_event_closure('button_release')\n    );\n    rubberband_canvas.addEventListener(\n        'dblclick',\n        on_mouse_event_closure('dblclick')\n    );\n    // Throttle sequential mouse events to 1 every 20ms.\n    rubberband_canvas.addEventListener(\n        'mousemove',\n        on_mouse_event_closure('motion_notify')\n    );\n\n    rubberband_canvas.addEventListener(\n        'mouseenter',\n        on_mouse_event_closure('figure_enter')\n    );\n    rubberband_canvas.addEventListener(\n        'mouseleave',\n        on_mouse_event_closure('figure_leave')\n    );\n\n    canvas_div.addEventListener('wheel', function (event) {\n        if (event.deltaY < 0) {\n            event.step = 1;\n        } else {\n            event.step = -1;\n        }\n        on_mouse_event_closure('scroll')(event);\n    });\n\n    canvas_div.appendChild(canvas);\n    canvas_div.appendChild(rubberband_canvas);\n\n    this.rubberband_context = rubberband_canvas.getContext('2d');\n    this.rubberband_context.strokeStyle = '#000000';\n\n    this._resize_canvas = function (width, height, forward) {\n        if (forward) {\n            canvas_div.style.width = width + 'px';\n            canvas_div.style.height = height + 'px';\n        }\n    };\n\n    // Disable right mouse context menu.\n    this.rubberband_canvas.addEventListener('contextmenu', function (_e) {\n        event.preventDefault();\n        return false;\n    });\n\n    function set_focus() {\n        canvas.focus();\n        canvas_div.focus();\n    }\n\n    window.setTimeout(set_focus, 100);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'mpl-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'mpl-button-group';\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'mpl-button-group';\n            continue;\n        }\n\n        var button = (fig.buttons[name] = document.createElement('button'));\n        button.classList = 'mpl-widget';\n        button.setAttribute('role', 'button');\n        button.setAttribute('aria-disabled', 'false');\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n\n        var icon_img = document.createElement('img');\n        icon_img.src = '_images/' + image + '.png';\n        icon_img.srcset = '_images/' + image + '_large.png 2x';\n        icon_img.alt = tooltip;\n        button.appendChild(icon_img);\n\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    var fmt_picker = document.createElement('select');\n    fmt_picker.classList = 'mpl-widget';\n    toolbar.appendChild(fmt_picker);\n    this.format_dropdown = fmt_picker;\n\n    for (var ind in mpl.extensions) {\n        var fmt = mpl.extensions[ind];\n        var option = document.createElement('option');\n        option.selected = fmt === mpl.default_extension;\n        option.innerHTML = fmt;\n        fmt_picker.appendChild(option);\n    }\n\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n};\n\nmpl.figure.prototype.request_resize = function (x_pixels, y_pixels) {\n    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n    // which will in turn request a refresh of the image.\n    this.send_message('resize', { width: x_pixels, height: y_pixels });\n};\n\nmpl.figure.prototype.send_message = function (type, properties) {\n    properties['type'] = type;\n    properties['figure_id'] = this.id;\n    this.ws.send(JSON.stringify(properties));\n};\n\nmpl.figure.prototype.send_draw_message = function () {\n    if (!this.waiting) {\n        this.waiting = true;\n        this.ws.send(JSON.stringify({ type: 'draw', figure_id: this.id }));\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    var format_dropdown = fig.format_dropdown;\n    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n    fig.ondownload(fig, format);\n};\n\nmpl.figure.prototype.handle_resize = function (fig, msg) {\n    var size = msg['size'];\n    if (size[0] !== fig.canvas.width || size[1] !== fig.canvas.height) {\n        fig._resize_canvas(size[0], size[1], msg['forward']);\n        fig.send_message('refresh', {});\n    }\n};\n\nmpl.figure.prototype.handle_rubberband = function (fig, msg) {\n    var x0 = msg['x0'] / fig.ratio;\n    var y0 = (fig.canvas.height - msg['y0']) / fig.ratio;\n    var x1 = msg['x1'] / fig.ratio;\n    var y1 = (fig.canvas.height - msg['y1']) / fig.ratio;\n    x0 = Math.floor(x0) + 0.5;\n    y0 = Math.floor(y0) + 0.5;\n    x1 = Math.floor(x1) + 0.5;\n    y1 = Math.floor(y1) + 0.5;\n    var min_x = Math.min(x0, x1);\n    var min_y = Math.min(y0, y1);\n    var width = Math.abs(x1 - x0);\n    var height = Math.abs(y1 - y0);\n\n    fig.rubberband_context.clearRect(\n        0,\n        0,\n        fig.canvas.width / fig.ratio,\n        fig.canvas.height / fig.ratio\n    );\n\n    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n};\n\nmpl.figure.prototype.handle_figure_label = function (fig, msg) {\n    // Updates the figure title.\n    fig.header.textContent = msg['label'];\n};\n\nmpl.figure.prototype.handle_cursor = function (fig, msg) {\n    fig.rubberband_canvas.style.cursor = msg['cursor'];\n};\n\nmpl.figure.prototype.handle_message = function (fig, msg) {\n    fig.message.textContent = msg['message'];\n};\n\nmpl.figure.prototype.handle_draw = function (fig, _msg) {\n    // Request the server to send over a new figure.\n    fig.send_draw_message();\n};\n\nmpl.figure.prototype.handle_image_mode = function (fig, msg) {\n    fig.image_mode = msg['mode'];\n};\n\nmpl.figure.prototype.handle_history_buttons = function (fig, msg) {\n    for (var key in msg) {\n        if (!(key in fig.buttons)) {\n            continue;\n        }\n        fig.buttons[key].disabled = !msg[key];\n        fig.buttons[key].setAttribute('aria-disabled', !msg[key]);\n    }\n};\n\nmpl.figure.prototype.handle_navigate_mode = function (fig, msg) {\n    if (msg['mode'] === 'PAN') {\n        fig.buttons['Pan'].classList.add('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    } else if (msg['mode'] === 'ZOOM') {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.add('active');\n    } else {\n        fig.buttons['Pan'].classList.remove('active');\n        fig.buttons['Zoom'].classList.remove('active');\n    }\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Called whenever the canvas gets updated.\n    this.send_message('ack', {});\n};\n\n// A function to construct a web socket function for onmessage handling.\n// Called in the figure constructor.\nmpl.figure.prototype._make_on_message_function = function (fig) {\n    return function socket_on_message(evt) {\n        if (evt.data instanceof Blob) {\n            var img = evt.data;\n            if (img.type !== 'image/png') {\n                /* FIXME: We get \"Resource interpreted as Image but\n                 * transferred with MIME type text/plain:\" errors on\n                 * Chrome.  But how to set the MIME type?  It doesn't seem\n                 * to be part of the websocket stream */\n                img.type = 'image/png';\n            }\n\n            /* Free the memory for the previous frames */\n            if (fig.imageObj.src) {\n                (window.URL || window.webkitURL).revokeObjectURL(\n                    fig.imageObj.src\n                );\n            }\n\n            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n                img\n            );\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        } else if (\n            typeof evt.data === 'string' &&\n            evt.data.slice(0, 21) === 'data:image/png;base64'\n        ) {\n            fig.imageObj.src = evt.data;\n            fig.updated_canvas_event();\n            fig.waiting = false;\n            return;\n        }\n\n        var msg = JSON.parse(evt.data);\n        var msg_type = msg['type'];\n\n        // Call the  \"handle_{type}\" callback, which takes\n        // the figure and JSON message as its only arguments.\n        try {\n            var callback = fig['handle_' + msg_type];\n        } catch (e) {\n            console.log(\n                \"No handler for the '\" + msg_type + \"' message type: \",\n                msg\n            );\n            return;\n        }\n\n        if (callback) {\n            try {\n                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n                callback(fig, msg);\n            } catch (e) {\n                console.log(\n                    \"Exception inside the 'handler_\" + msg_type + \"' callback:\",\n                    e,\n                    e.stack,\n                    msg\n                );\n            }\n        }\n    };\n};\n\n// from https://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\nmpl.findpos = function (e) {\n    //this section is from http://www.quirksmode.org/js/events_properties.html\n    var targ;\n    if (!e) {\n        e = window.event;\n    }\n    if (e.target) {\n        targ = e.target;\n    } else if (e.srcElement) {\n        targ = e.srcElement;\n    }\n    if (targ.nodeType === 3) {\n        // defeat Safari bug\n        targ = targ.parentNode;\n    }\n\n    // pageX,Y are the mouse positions relative to the document\n    var boundingRect = targ.getBoundingClientRect();\n    var x = e.pageX - (boundingRect.left + document.body.scrollLeft);\n    var y = e.pageY - (boundingRect.top + document.body.scrollTop);\n\n    return { x: x, y: y };\n};\n\n/*\n * return a copy of an object with only non-object keys\n * we need this to avoid circular references\n * https://stackoverflow.com/a/24161582/3208463\n */\nfunction simpleKeys(original) {\n    return Object.keys(original).reduce(function (obj, key) {\n        if (typeof original[key] !== 'object') {\n            obj[key] = original[key];\n        }\n        return obj;\n    }, {});\n}\n\nmpl.figure.prototype.mouse_event = function (event, name) {\n    var canvas_pos = mpl.findpos(event);\n\n    if (name === 'button_press') {\n        this.canvas.focus();\n        this.canvas_div.focus();\n    }\n\n    var x = canvas_pos.x * this.ratio;\n    var y = canvas_pos.y * this.ratio;\n\n    this.send_message(name, {\n        x: x,\n        y: y,\n        button: event.button,\n        step: event.step,\n        guiEvent: simpleKeys(event),\n    });\n\n    /* This prevents the web browser from automatically changing to\n     * the text insertion cursor when the button is pressed.  We want\n     * to control all of the cursor setting manually through the\n     * 'cursor' event from matplotlib */\n    event.preventDefault();\n    return false;\n};\n\nmpl.figure.prototype._key_event_extra = function (_event, _name) {\n    // Handle any extra behaviour associated with a key event\n};\n\nmpl.figure.prototype.key_event = function (event, name) {\n    // Prevent repeat events\n    if (name === 'key_press') {\n        if (event.key === this._key) {\n            return;\n        } else {\n            this._key = event.key;\n        }\n    }\n    if (name === 'key_release') {\n        this._key = null;\n    }\n\n    var value = '';\n    if (event.ctrlKey && event.key !== 'Control') {\n        value += 'ctrl+';\n    }\n    else if (event.altKey && event.key !== 'Alt') {\n        value += 'alt+';\n    }\n    else if (event.shiftKey && event.key !== 'Shift') {\n        value += 'shift+';\n    }\n\n    value += 'k' + event.key;\n\n    this._key_event_extra(event, name);\n\n    this.send_message(name, { key: value, guiEvent: simpleKeys(event) });\n    return false;\n};\n\nmpl.figure.prototype.toolbar_button_onclick = function (name) {\n    if (name === 'download') {\n        this.handle_save(this, null);\n    } else {\n        this.send_message('toolbar_button', { name: name });\n    }\n};\n\nmpl.figure.prototype.toolbar_button_onmouseover = function (tooltip) {\n    this.message.textContent = tooltip;\n};\n\n///////////////// REMAINING CONTENT GENERATED BY embed_js.py /////////////////\n// prettier-ignore\nvar _JSXTOOLS_RESIZE_OBSERVER=function(A){var t,i=new WeakMap,n=new WeakMap,a=new WeakMap,r=new WeakMap,o=new Set;function s(e){if(!(this instanceof s))throw new TypeError(\"Constructor requires 'new' operator\");i.set(this,e)}function h(){throw new TypeError(\"Function is not a constructor\")}function c(e,t,i,n){e=0 in arguments?Number(arguments[0]):0,t=1 in arguments?Number(arguments[1]):0,i=2 in arguments?Number(arguments[2]):0,n=3 in arguments?Number(arguments[3]):0,this.right=(this.x=this.left=e)+(this.width=i),this.bottom=(this.y=this.top=t)+(this.height=n),Object.freeze(this)}function d(){t=requestAnimationFrame(d);var s=new WeakMap,p=new Set;o.forEach((function(t){r.get(t).forEach((function(i){var r=t instanceof window.SVGElement,o=a.get(t),d=r?0:parseFloat(o.paddingTop),f=r?0:parseFloat(o.paddingRight),l=r?0:parseFloat(o.paddingBottom),u=r?0:parseFloat(o.paddingLeft),g=r?0:parseFloat(o.borderTopWidth),m=r?0:parseFloat(o.borderRightWidth),w=r?0:parseFloat(o.borderBottomWidth),b=u+f,F=d+l,v=(r?0:parseFloat(o.borderLeftWidth))+m,W=g+w,y=r?0:t.offsetHeight-W-t.clientHeight,E=r?0:t.offsetWidth-v-t.clientWidth,R=b+v,z=F+W,M=r?t.width:parseFloat(o.width)-R-E,O=r?t.height:parseFloat(o.height)-z-y;if(n.has(t)){var k=n.get(t);if(k[0]===M&&k[1]===O)return}n.set(t,[M,O]);var S=Object.create(h.prototype);S.target=t,S.contentRect=new c(u,d,M,O),s.has(i)||(s.set(i,[]),p.add(i)),s.get(i).push(S)}))})),p.forEach((function(e){i.get(e).call(e,s.get(e),e)}))}return s.prototype.observe=function(i){if(i instanceof window.Element){r.has(i)||(r.set(i,new Set),o.add(i),a.set(i,window.getComputedStyle(i)));var n=r.get(i);n.has(this)||n.add(this),cancelAnimationFrame(t),t=requestAnimationFrame(d)}},s.prototype.unobserve=function(i){if(i instanceof window.Element&&r.has(i)){var n=r.get(i);n.has(this)&&(n.delete(this),n.size||(r.delete(i),o.delete(i))),n.size||r.delete(i),o.size||cancelAnimationFrame(t)}},A.DOMRectReadOnly=c,A.ResizeObserver=s,A.ResizeObserverEntry=h,A}; // eslint-disable-line\nmpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\\nx/y fixes axis\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n\nmpl.extensions = [\"eps\", \"jpeg\", \"pgf\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n\nmpl.default_extension = \"png\";/* global mpl */\n\nvar comm_websocket_adapter = function (comm) {\n    // Create a \"websocket\"-like object which calls the given IPython comm\n    // object with the appropriate methods. Currently this is a non binary\n    // socket, so there is still some room for performance tuning.\n    var ws = {};\n\n    ws.binaryType = comm.kernel.ws.binaryType;\n    ws.readyState = comm.kernel.ws.readyState;\n    function updateReadyState(_event) {\n        if (comm.kernel.ws) {\n            ws.readyState = comm.kernel.ws.readyState;\n        } else {\n            ws.readyState = 3; // Closed state.\n        }\n    }\n    comm.kernel.ws.addEventListener('open', updateReadyState);\n    comm.kernel.ws.addEventListener('close', updateReadyState);\n    comm.kernel.ws.addEventListener('error', updateReadyState);\n\n    ws.close = function () {\n        comm.close();\n    };\n    ws.send = function (m) {\n        //console.log('sending', m);\n        comm.send(m);\n    };\n    // Register the callback with on_msg.\n    comm.on_msg(function (msg) {\n        //console.log('receiving', msg['content']['data'], msg);\n        var data = msg['content']['data'];\n        if (data['blob'] !== undefined) {\n            data = {\n                data: new Blob(msg['buffers'], { type: data['blob'] }),\n            };\n        }\n        // Pass the mpl event to the overridden (by mpl) onmessage function.\n        ws.onmessage(data);\n    });\n    return ws;\n};\n\nmpl.mpl_figure_comm = function (comm, msg) {\n    // This is the function which gets called when the mpl process\n    // starts-up an IPython Comm through the \"matplotlib\" channel.\n\n    var id = msg.content.data.id;\n    // Get hold of the div created by the display call when the Comm\n    // socket was opened in Python.\n    var element = document.getElementById(id);\n    var ws_proxy = comm_websocket_adapter(comm);\n\n    function ondownload(figure, _format) {\n        window.open(figure.canvas.toDataURL());\n    }\n\n    var fig = new mpl.figure(id, ws_proxy, ondownload, element);\n\n    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n    // web socket which is closed, not our websocket->open comm proxy.\n    ws_proxy.onopen();\n\n    fig.parent_element = element;\n    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n    if (!fig.cell_info) {\n        console.error('Failed to find cell for figure', id, fig);\n        return;\n    }\n    fig.cell_info[0].output_area.element.on(\n        'cleared',\n        { fig: fig },\n        fig._remove_fig_handler\n    );\n};\n\nmpl.figure.prototype.handle_close = function (fig, msg) {\n    var width = fig.canvas.width / fig.ratio;\n    fig.cell_info[0].output_area.element.off(\n        'cleared',\n        fig._remove_fig_handler\n    );\n    fig.resizeObserverInstance.unobserve(fig.canvas_div);\n\n    // Update the output cell to use the data from the current canvas.\n    fig.push_to_output();\n    var dataURL = fig.canvas.toDataURL();\n    // Re-enable the keyboard manager in IPython - without this line, in FF,\n    // the notebook keyboard shortcuts fail.\n    IPython.keyboard_manager.enable();\n    fig.parent_element.innerHTML =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n    fig.close_ws(fig, msg);\n};\n\nmpl.figure.prototype.close_ws = function (fig, msg) {\n    fig.send_message('closing', msg);\n    // fig.ws.close()\n};\n\nmpl.figure.prototype.push_to_output = function (_remove_interactive) {\n    // Turn the data on the canvas into data in the output cell.\n    var width = this.canvas.width / this.ratio;\n    var dataURL = this.canvas.toDataURL();\n    this.cell_info[1]['text/html'] =\n        '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n};\n\nmpl.figure.prototype.updated_canvas_event = function () {\n    // Tell IPython that the notebook contents must change.\n    IPython.notebook.set_dirty(true);\n    this.send_message('ack', {});\n    var fig = this;\n    // Wait a second, then push the new image to the DOM so\n    // that it is saved nicely (might be nice to debounce this).\n    setTimeout(function () {\n        fig.push_to_output();\n    }, 1000);\n};\n\nmpl.figure.prototype._init_toolbar = function () {\n    var fig = this;\n\n    var toolbar = document.createElement('div');\n    toolbar.classList = 'btn-toolbar';\n    this.root.appendChild(toolbar);\n\n    function on_click_closure(name) {\n        return function (_event) {\n            return fig.toolbar_button_onclick(name);\n        };\n    }\n\n    function on_mouseover_closure(tooltip) {\n        return function (event) {\n            if (!event.currentTarget.disabled) {\n                return fig.toolbar_button_onmouseover(tooltip);\n            }\n        };\n    }\n\n    fig.buttons = {};\n    var buttonGroup = document.createElement('div');\n    buttonGroup.classList = 'btn-group';\n    var button;\n    for (var toolbar_ind in mpl.toolbar_items) {\n        var name = mpl.toolbar_items[toolbar_ind][0];\n        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n        var image = mpl.toolbar_items[toolbar_ind][2];\n        var method_name = mpl.toolbar_items[toolbar_ind][3];\n\n        if (!name) {\n            /* Instead of a spacer, we start a new button group. */\n            if (buttonGroup.hasChildNodes()) {\n                toolbar.appendChild(buttonGroup);\n            }\n            buttonGroup = document.createElement('div');\n            buttonGroup.classList = 'btn-group';\n            continue;\n        }\n\n        button = fig.buttons[name] = document.createElement('button');\n        button.classList = 'btn btn-default';\n        button.href = '#';\n        button.title = name;\n        button.innerHTML = '<i class=\"fa ' + image + ' fa-lg\"></i>';\n        button.addEventListener('click', on_click_closure(method_name));\n        button.addEventListener('mouseover', on_mouseover_closure(tooltip));\n        buttonGroup.appendChild(button);\n    }\n\n    if (buttonGroup.hasChildNodes()) {\n        toolbar.appendChild(buttonGroup);\n    }\n\n    // Add the status bar.\n    var status_bar = document.createElement('span');\n    status_bar.classList = 'mpl-message pull-right';\n    toolbar.appendChild(status_bar);\n    this.message = status_bar;\n\n    // Add the close button to the window.\n    var buttongrp = document.createElement('div');\n    buttongrp.classList = 'btn-group inline pull-right';\n    button = document.createElement('button');\n    button.classList = 'btn btn-mini btn-primary';\n    button.href = '#';\n    button.title = 'Stop Interaction';\n    button.innerHTML = '<i class=\"fa fa-power-off icon-remove icon-large\"></i>';\n    button.addEventListener('click', function (_evt) {\n        fig.handle_close(fig, {});\n    });\n    button.addEventListener(\n        'mouseover',\n        on_mouseover_closure('Stop Interaction')\n    );\n    buttongrp.appendChild(button);\n    var titlebar = this.root.querySelector('.ui-dialog-titlebar');\n    titlebar.insertBefore(buttongrp, titlebar.firstChild);\n};\n\nmpl.figure.prototype._remove_fig_handler = function (event) {\n    var fig = event.data.fig;\n    if (event.target !== this) {\n        // Ignore bubbled events from children.\n        return;\n    }\n    fig.close_ws(fig, {});\n};\n\nmpl.figure.prototype._root_extra_style = function (el) {\n    el.style.boxSizing = 'content-box'; // override notebook setting of border-box.\n};\n\nmpl.figure.prototype._canvas_extra_style = function (el) {\n    // this is important to make the div 'focusable\n    el.setAttribute('tabindex', 0);\n    // reach out to IPython and tell the keyboard manager to turn it's self\n    // off when our div gets focus\n\n    // location in version 3\n    if (IPython.notebook.keyboard_manager) {\n        IPython.notebook.keyboard_manager.register_events(el);\n    } else {\n        // location in version 2\n        IPython.keyboard_manager.register_events(el);\n    }\n};\n\nmpl.figure.prototype._key_event_extra = function (event, _name) {\n    // Check for shift+enter\n    if (event.shiftKey && event.which === 13) {\n        this.canvas_div.blur();\n        // select the cell after this one\n        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n        IPython.notebook.select(index + 1);\n    }\n};\n\nmpl.figure.prototype.handle_save = function (fig, _msg) {\n    fig.ondownload(fig, null);\n};\n\nmpl.find_output_cell = function (html_output) {\n    // Return the cell and output element which can be found *uniquely* in the notebook.\n    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n    // IPython event is triggered only after the cells have been serialised, which for\n    // our purposes (turning an active figure into a static one), is too late.\n    var cells = IPython.notebook.get_cells();\n    var ncells = cells.length;\n    for (var i = 0; i < ncells; i++) {\n        var cell = cells[i];\n        if (cell.cell_type === 'code') {\n            for (var j = 0; j < cell.output_area.outputs.length; j++) {\n                var data = cell.output_area.outputs[j];\n                if (data.data) {\n                    // IPython >= 3 moved mimebundle to data attribute of output\n                    data = data.data;\n                }\n                if (data['text/html'] === html_output) {\n                    return [cell, data, j];\n                }\n            }\n        }\n    }\n};\n\n// Register the function which deals with the matplotlib target/channel.\n// The kernel may be null if the page has been refreshed.\nif (IPython.notebook.kernel !== null) {\n    IPython.notebook.kernel.comm_manager.register_target(\n        'matplotlib',\n        mpl.mpl_figure_comm\n    );\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='47b382b0-aba6-44ab-bd6a-a028db240637'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 0 | Loss 0.5004482269287109 | Network in: tensor([[0, 1]])| Network out: tensor([0.4854, 0.4854], grad_fn=<SqueezeBackward1>) \n",
      " Epoch 100 | Loss 0.500055193901062 | Network in: tensor([[0, 1]])| Network out: tensor([0.4950, 0.4950], grad_fn=<SqueezeBackward1>) \n",
      " Epoch 200 | Loss 0.4999985992908478 | Network in: tensor([[1, 0]])| Network out: tensor([0.4992, 0.4992], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 300 | Loss 0.5000019669532776 | Network in: tensor([[0, 1]])| Network out: tensor([0.5002, 0.5002], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 400 | Loss 0.5000020861625671 | Network in: tensor([[0, 1]])| Network out: tensor([0.5002, 0.5002], grad_fn=<SqueezeBackward1>) \n",
      " Epoch 500 | Loss 0.5000020265579224 | Network in: tensor([[0, 1]])| Network out: tensor([0.5002, 0.5002], grad_fn=<SqueezeBackward1>) \n",
      " Epoch 600 | Loss 0.4999980330467224 | Network in: tensor([[1, 0]])| Network out: tensor([0.4998, 0.4998], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 700 | Loss 0.5000021457672119 | Network in: tensor([[0, 1]])| Network out: tensor([0.5002, 0.5002], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 800 | Loss 0.49999794363975525 | Network in: tensor([[1, 0]])| Network out: tensor([0.4999, 0.4999], grad_fn=<SqueezeBackward1>) \n",
      " Epoch 900 | Loss 0.49999794363975525 | Network in: tensor([[1, 0]])| Network out: tensor([0.4999, 0.4999], grad_fn=<SqueezeBackward1>) \n",
      " Epoch 1000 | Loss 0.5000021457672119 | Network in: tensor([[0, 1]])| Network out: tensor([0.5002, 0.5002], grad_fn=<SqueezeBackward1>) \n",
      " Epoch 1100 | Loss 0.49999791383743286 | Network in: tensor([[1, 0]])| Network out: tensor([0.4999, 0.4999], grad_fn=<SqueezeBackward1>) \n",
      " Epoch 1200 | Loss 0.4999980330467224 | Network in: tensor([[1, 0]])| Network out: tensor([0.4999, 0.4999], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 1300 | Loss 0.49999797344207764 | Network in: tensor([[1, 0]])| Network out: tensor([0.4999, 0.4999], grad_fn=<SqueezeBackward1>) \n",
      " Epoch 1400 | Loss 0.49999797344207764 | Network in: tensor([[1, 0]])| Network out: tensor([0.4999, 0.4999], grad_fn=<SqueezeBackward1>) \n",
      " Epoch 1500 | Loss 0.4999980032444 | Network in: tensor([[1, 0]])| Network out: tensor([0.4999, 0.4999], grad_fn=<SqueezeBackward1>) >)  \n",
      " Epoch 1600 | Loss 0.4999980032444 | Network in: tensor([[1, 0]])| Network out: tensor([0.4999, 0.4999], grad_fn=<SqueezeBackward1>) 1>) \n",
      " Epoch 1700 | Loss 0.5000020265579224 | Network in: tensor([[0, 1]])| Network out: tensor([0.5002, 0.5002], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 1800 | Loss 0.5000020265579224 | Network in: tensor([[0, 1]])| Network out: tensor([0.5002, 0.5002], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 1900 | Loss 0.5000021457672119 | Network in: tensor([[0, 1]])| Network out: tensor([0.5002, 0.5002], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 2000 | Loss 0.4999977648258209 | Network in: tensor([[1, 0]])| Network out: tensor([0.4999, 0.4999], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 2100 | Loss 0.5000021457672119 | Network in: tensor([[0, 1]])| Network out: tensor([0.5002, 0.5002], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 2200 | Loss 0.4999978244304657 | Network in: tensor([[1, 0]])| Network out: tensor([0.4999, 0.4999], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 2300 | Loss 0.5000020861625671 | Network in: tensor([[0, 1]])| Network out: tensor([0.5002, 0.5002], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 2400 | Loss 0.5000021457672119 | Network in: tensor([[0, 1]])| Network out: tensor([0.5002, 0.5002], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 2500 | Loss 0.4999978840351105 | Network in: tensor([[1, 0]])| Network out: tensor([0.4999, 0.4999], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 2600 | Loss 0.5000020265579224 | Network in: tensor([[0, 1]])| Network out: tensor([0.5002, 0.5002], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 2700 | Loss 0.5000019073486328 | Network in: tensor([[0, 1]])| Network out: tensor([0.5002, 0.5002], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 2800 | Loss 0.5000017881393433 | Network in: tensor([[0, 1]])| Network out: tensor([0.5001, 0.5001], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 2900 | Loss 0.4999982714653015 | Network in: tensor([[1, 0]])| Network out: tensor([0.4999, 0.4999], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 3000 | Loss 0.4999983012676239 | Network in: tensor([[1, 0]])| Network out: tensor([0.4999, 0.4999], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 3100 | Loss 0.4999983012676239 | Network in: tensor([[1, 0]])| Network out: tensor([0.4999, 0.4999], grad_fn=<SqueezeBackward1>) \n",
      " Epoch 3200 | Loss 0.5000019669532776 | Network in: tensor([[0, 1]])| Network out: tensor([0.5001, 0.5001], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 3300 | Loss 0.4999980032444 | Network in: tensor([[1, 0]])| Network out: tensor([0.4999, 0.4999], grad_fn=<SqueezeBackward1>) >)  \n",
      " Epoch 3400 | Loss 0.5000021457672119 | Network in: tensor([[0, 1]])| Network out: tensor([0.5001, 0.5001], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 3500 | Loss 0.49999797344207764 | Network in: tensor([[1, 0]])| Network out: tensor([0.4999, 0.4999], grad_fn=<SqueezeBackward1>) \n",
      " Epoch 3600 | Loss 0.5000020265579224 | Network in: tensor([[0, 1]])| Network out: tensor([0.5001, 0.5001], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 3700 | Loss 0.5000019669532776 | Network in: tensor([[0, 1]])| Network out: tensor([0.5001, 0.5001], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 3800 | Loss 0.5000020861625671 | Network in: tensor([[0, 1]])| Network out: tensor([0.5001, 0.5001], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 3900 | Loss 0.49999794363975525 | Network in: tensor([[1, 0]])| Network out: tensor([0.4999, 0.4999], grad_fn=<SqueezeBackward1>) \n",
      " Epoch 4000 | Loss 0.4999980032444 | Network in: tensor([[1, 0]])| Network out: tensor([0.4999, 0.4999], grad_fn=<SqueezeBackward1>) >)  \n",
      " Epoch 4100 | Loss 0.500001847743988 | Network in: tensor([[0, 1]])| Network out: tensor([0.5001, 0.5001], grad_fn=<SqueezeBackward1>) ) \n",
      " Epoch 4200 | Loss 0.5000017285346985 | Network in: tensor([[0, 1]])| Network out: tensor([0.5001, 0.5001], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 4300 | Loss 0.49999842047691345 | Network in: tensor([[1, 0]])| Network out: tensor([0.4999, 0.4999], grad_fn=<SqueezeBackward1>) \n",
      " Epoch 4400 | Loss 0.4999984800815582 | Network in: tensor([[1, 0]])| Network out: tensor([0.4999, 0.4999], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 4500 | Loss 0.4999985694885254 | Network in: tensor([[1, 0]])| Network out: tensor([0.4999, 0.4999], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 4600 | Loss 0.5000014901161194 | Network in: tensor([[0, 1]])| Network out: tensor([0.5001, 0.5001], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 4700 | Loss 0.5000014305114746 | Network in: tensor([[0, 1]])| Network out: tensor([0.5001, 0.5001], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 4800 | Loss 0.5000013113021851 | Network in: tensor([[0, 1]])| Network out: tensor([0.5001, 0.5001], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 4900 | Loss 0.5000013113021851 | Network in: tensor([[0, 1]])| Network out: tensor([0.5001, 0.5001], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 5000 | Loss 0.5000013113021851 | Network in: tensor([[0, 1]])| Network out: tensor([0.5001, 0.5001], grad_fn=<SqueezeBackward1>)  \n",
      " Epoch 5083 | Loss 0.49999862909317017 | Network in: tensor([[1, 0]])| Network out: tensor([0.4999, 0.4999], grad_fn=<SqueezeBackward1>) "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lmacl\\Google Drive\\GitHub\\Pytorch-Geometric-Neural-Automata\\test.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 61>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W2sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     output_node_data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(problem_data_y\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W2sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m     \u001b[39m# else:\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W2sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m     \u001b[39m# output_node_data = problem_data_y\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W2sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m     x \u001b[39m=\u001b[39m update_rule(x, edge_index, problem_data_x\u001b[39m.\u001b[39;49mfloat())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W2sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m \u001b[39m# if idx == len(dataset_loader)-1:\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W2sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m \u001b[39m# print(problem_data_x,network_output)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W2sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m network_output \u001b[39m=\u001b[39m update_rule\u001b[39m.\u001b[39mget_output(x)\n",
      "File \u001b[1;32mc:\\Users\\lmacl\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\lmacl\\Google Drive\\GitHub\\Pytorch-Geometric-Neural-Automata\\test.ipynb Cell 3\u001b[0m in \u001b[0;36mUpdateRule.forward\u001b[1;34m(self, x, edge_index, input_data)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W2sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W2sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39m# x = x.relu()\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W2sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhidden_rule_layers(x, edge_index)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W2sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39m# x = self.conv2(x, edge_index)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lmacl/Google%20Drive/GitHub/Pytorch-Geometric-Neural-Automata/test.ipynb#W2sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_out(x, edge_index)\n",
      "File \u001b[1;32mc:\\Users\\lmacl\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Temp\\lmacl_pyg\\tmp76v8r0t2.py:24\u001b[0m, in \u001b[0;36mSequential_6e9ca1.forward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m     22\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule_4(x, edge_index)\n\u001b[0;32m     23\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule_5(x)\n\u001b[1;32m---> 24\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule_6(x, edge_index)\n\u001b[0;32m     25\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule_7(x)\n\u001b[0;32m     26\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\lmacl\\miniconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\lmacl\\miniconda3\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:172\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    170\u001b[0m cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_edge_index\n\u001b[0;32m    171\u001b[0m \u001b[39mif\u001b[39;00m cache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m     edge_index, edge_weight \u001b[39m=\u001b[39m gcn_norm(  \u001b[39m# yapf: disable\u001b[39;49;00m\n\u001b[0;32m    173\u001b[0m         edge_index, edge_weight, x\u001b[39m.\u001b[39;49msize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_dim),\n\u001b[0;32m    174\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimproved, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_self_loops)\n\u001b[0;32m    175\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached:\n\u001b[0;32m    176\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_edge_index \u001b[39m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[1;32mc:\\Users\\lmacl\\miniconda3\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:54\u001b[0m, in \u001b[0;36mgcn_norm\u001b[1;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, dtype)\u001b[0m\n\u001b[0;32m     51\u001b[0m num_nodes \u001b[39m=\u001b[39m maybe_num_nodes(edge_index, num_nodes)\n\u001b[0;32m     53\u001b[0m \u001b[39mif\u001b[39;00m edge_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     edge_weight \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mones((edge_index\u001b[39m.\u001b[39;49msize(\u001b[39m1\u001b[39;49m), ), dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m     55\u001b[0m                              device\u001b[39m=\u001b[39;49medge_index\u001b[39m.\u001b[39;49mdevice)\n\u001b[0;32m     57\u001b[0m \u001b[39mif\u001b[39;00m add_self_loops:\n\u001b[0;32m     58\u001b[0m     edge_index, tmp_edge_weight \u001b[39m=\u001b[39m add_remaining_self_loops(\n\u001b[0;32m     59\u001b[0m         edge_index, edge_weight, fill_value, num_nodes)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "from utils import reset_inputs, get_type, remove_type, get_output\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "\n",
    "\n",
    "class SelfOrganizeTest(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    If Rule can learn this data, then it can somewhat self organize\n",
    "    \"\"\"\n",
    "    def __init__(self) :\n",
    "        super().__init__()\n",
    "        self.data = torch.tensor([[0,1], [1,0]])\n",
    "        self.target = torch.tensor([[0,1], [1,0]])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.target[index]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class ANDDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        # self.data = torch.tensor([[-1,-1], [-1,1], [1,-1], [1,1]])\n",
    "        # self.target = [-1,1,1,-1]\n",
    "        self.data = torch.tensor([[0,0], [1,1],[0,0], [1,1]])\n",
    "        self.target = torch.tensor([[0],[1],[0],[1]])\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.target[index]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "class TranslateDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.data = torch.tensor([[1,0,0,0], [0,1,0,0], [0,0,1,0], [0,0,0,1]])\n",
    "        self.target = torch.tensor([[0,1,0,0], [0,0,1,0], [0,0,0,1], [1,0,0,0]])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.target[index]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "        \n",
    "dataset_loader = DataLoader(SelfOrganizeTest(), batch_size=1, shuffle=True)\n",
    "# dataset_loader = DataLoader(ANDDataset(), batch_size=1, shuffle=False)\n",
    "# dataset_loader = DataLoader(TranslateDataset(), batch_size=1, shuffle=True)\n",
    "\n",
    "update_rule = UpdateRule()\n",
    "\n",
    "optimizer = torch.optim.Adam(update_rule.parameters(), lr=0.0001)\n",
    "\n",
    "losses = []\n",
    "n_steps = 1\n",
    "batch_size = 1\n",
    "for epoch in range(10000):\n",
    "    loss = 0\n",
    "    for _ in range(batch_size):\n",
    "        update_rule.reset() \n",
    "        \n",
    "        batch_loss = 0\n",
    "        x = data.x.float().clone()\n",
    "        x[x == -1] = torch.zeros(n_nodes * hidden_dim)\n",
    "        edge_index = data.edge_index.long().clone()\n",
    "        \n",
    "        for idx, (problem_data_x, problem_data_y) in enumerate(dataset_loader):\n",
    "           \n",
    "            for i in range(n_steps):\n",
    "                # if idx == len(dataset_loader)-1:\n",
    "                output_node_data = torch.zeros(problem_data_y.shape)\n",
    "                # else:\n",
    "                # output_node_data = problem_data_y\n",
    "                x = update_rule(x, edge_index, problem_data_x.float())\n",
    "                \n",
    "            \n",
    "            # if idx == len(dataset_loader)-1:\n",
    "            # print(problem_data_x,network_output)\n",
    "            network_output = update_rule.get_output(x)\n",
    "            batch_loss += F.mse_loss(problem_data_y.float().squeeze(0), network_output)\n",
    "         \n",
    "        loss += batch_loss\n",
    "    \n",
    "    loss /= batch_size\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "        \n",
    "    loss.backward()  \n",
    "    # update_rule.print_grad()\n",
    "    optimizer.step()  \n",
    "    optimizer.zero_grad()  \n",
    "    print(f\"\\r Epoch {epoch * batch_size} | Loss {loss} | Network in: {problem_data_x}| Network out: {network_output} \", end=\"\")\n",
    "    \n",
    "    if epoch % (100 // batch_size) == 0:\n",
    "        print()\n",
    "\n",
    "ax.clear()\n",
    "ax.plot(losses)\n",
    "fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])\n",
      "tensor([0.4811, 0.4811], grad_fn=<SqueezeBackward1>)\n",
      "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])\n",
      "tensor([0.4810, 0.4810], grad_fn=<SqueezeBackward1>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.4810, 0.4810], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "\n",
    "def run_rule(data_x, update_rule, n_steps = 2):\n",
    "    x = data.x.float().clone()\n",
    "    x[x == -1] = torch.zeros(n_nodes * hidden_dim)\n",
    "    update_rule.reset()\n",
    "    edge_index = data.edge_index.long().clone()\n",
    "    for i in range(n_steps):\n",
    "        x = update_rule(x, edge_index, data_x.float())\n",
    "    \n",
    "        network_output = update_rule.get_output(x)\n",
    "        print(network_output)\n",
    "    return network_output\n",
    "    \n",
    "\n",
    "run_rule(torch.tensor([[0, 1]]), update_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 1., 2., 3., 4.],\n",
       "        [1., 2., 3., 4., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_index = data.edge_index\n",
    "edge_index\n",
    "torch.tensor([[0., 0., 0., 0., 1., 2., 3., 4.],\n",
    "        [1., 2., 3., 4., 0., 0., 0., 0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  1,  1,  2,  2,  3,  3,  4,  5,  6,  7,  8,  0,  1,  2,  3,  4,\n",
       "          0,  1,  2,  3,  4,  9,  8,  7,  6,  5,  9,  8,  7,  6,  5,  5,  1,  6,\n",
       "          2,  7,  3,  8,  4,  9,  6,  7,  8,  9, 10, 10, 10, 10, 10, 11, 11, 11,\n",
       "         11, 11, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13,  5,  1,  6,  2,  7,  3,\n",
       "          8,  4,  9,  6,  7,  8,  9, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 12,\n",
       "         12, 12, 12, 12, 13, 13, 13, 13, 13,  0,  0,  1,  1,  2,  2,  3,  3,  4,\n",
       "          5,  6,  7,  8,  0,  1,  2,  3,  4,  0,  1,  2,  3,  4,  9,  8,  7,  6,\n",
       "          5,  9,  8,  7,  6,  5],\n",
       "        [ 5,  1,  6,  2,  7,  3,  8,  4,  9,  6,  7,  8,  9, 10, 10, 10, 10, 10,\n",
       "         11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13,  0,  0,  1,\n",
       "          1,  2,  2,  3,  3,  4,  5,  6,  7,  8,  0,  1,  2,  3,  4,  0,  1,  2,\n",
       "          3,  4,  9,  8,  7,  6,  5,  9,  8,  7,  6,  5,  0,  0,  1,  1,  2,  2,\n",
       "          3,  3,  4,  5,  6,  7,  8,  0,  1,  2,  3,  4,  0,  1,  2,  3,  4,  9,\n",
       "          8,  7,  6,  5,  9,  8,  7,  6,  5,  5,  1,  6,  2,  7,  3,  8,  4,  9,\n",
       "          6,  7,  8,  9, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 12, 12, 12, 12,\n",
       "         12, 13, 13, 13, 13, 13]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((torch.concat((edge_index[0], edge_index[1]), 0), torch.concat((edge_index[1], edge_index[0]), 0)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2513499229.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [13]\u001b[1;36m\u001b[0m\n\u001b[1;33m    [(GCNConv(width, width), 'x, edge_index -> x'), ReLU() for x in range(5)]\u001b[0m\n\u001b[1;37m                                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "[(GCNConv(width, width), 'x, edge_index -> x'), ReLU() for x in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(GCNConv(1, 1), 'x, edge_index -> x'),\n",
       " ReLU(),\n",
       " (GCNConv(1, 1), 'x, edge_index -> x'),\n",
       " ReLU(),\n",
       " (GCNConv(1, 1), 'x, edge_index -> x'),\n",
       " ReLU()]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for i in range(3) for x in [(GCNConv(width, width), 'x, edge_index -> x'), ReLU()]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8645a3289b338b219b448912b5fab165e90ac259118b71d23942463e3b992b2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
