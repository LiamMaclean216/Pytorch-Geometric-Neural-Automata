{"cells":[{"cell_type":"markdown","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":112977,"status":"ok","timestamp":1666709139614,"user":{"displayName":"Liam Maclean","userId":"16471805810852624957"},"user_tz":240},"id":"ZXja8iz8lEON","outputId":"cc7033ca-6ef4-4c25-e788-cb6dcafee493"},"source":["!conda install --file /content/drive/MyDrive/GitHub/Pytorch-Geometric-Neural-Automata/requirements.txt\n","import sys\n","sys.path.insert(0,'/content/drive/MyDrive/GitHub/Pytorch-Geometric-Neural-Automata/')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# conda install pytorch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0 -c pytorch -y & conda install pyg -c pyg -y & conda install -c anaconda networkx -y & conda install -c conda-forge matplotlib -y\n","import wandb\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from torch_geometric.data import Data\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","import torch_geometric.utils as utils\n","from utils import *\n","from model import UpdateRule\n","from datasets import *\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class D():\n","    def __init__(self, datasets):\n","        self.datasets = datasets\n","        # self.datasets = [Dataset(data=torch.tensor([[0,1,0]]), target=torch.tensor([[0,1,0]]))]#, TranslateDataset(1, n=n)]\n","        \n","        self.batch_size = 1\n","    \n","    def __iter__(self):\n","        # for problem_x, problem_y in zip(TDataset1().data, TDataset2().data), zip(TDataset1().target, TDataset2().target):\n","        \n","        new_idx = torch.randperm(len(self.datasets))\n","        self.datasets = [self.datasets[i].shuffle() for i in new_idx]\n","        \n","        datasets_in_batch = [self.datasets[i % len(self.datasets)].shuffle() for i in range(self.batch_size)]\n","        \n","        for x in zip(*([d.data for d in datasets_in_batch] + [d.target for d in datasets_in_batch])):\n","            yield torch.stack(x[0:len(datasets_in_batch)]), torch.stack(x[len(datasets_in_batch):])\n","            \n","    def __len__(self):\n","        return len(self.datasets)\n","    \n","    def iterate(self):\n","        \"\"\"\n","        returns a generator that gives an shuffled index\n","        \"\"\"\n","        self.init()\n","        return iter(torch.randperm(len(self.datasets)))\n","\n","    @property\n","    def n_inputs(self):\n","        return self.datasets[0].data.shape[1]\n","\n","    @property\n","    def n_outputs(self):\n","        return self.datasets[0].target.shape[1]\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"executionInfo":{"elapsed":2634,"status":"error","timestamp":1666709143193,"user":{"displayName":"Liam Maclean","userId":"16471805810852624957"},"user_tz":240},"id":"O646_XlilAVb","outputId":"b18585d5-d1e1-41f8-e056-cc0d5b35ed92"},"outputs":[],"source":["\n","n= 5\n","# training_set = D([\n","#     TranslateDataset(0, n=n)#, TranslateDataset(2, n=n), TranslateDataset(-2, n=n), TranslateDataset(1, n=n)\n","# ])\n","training_set = D([\n","    # Dataset(\n","    #     [[0,1,0,1,0], [1,0,0,0,1], [1,0,1,0,0], [1,0,0,1,0]],\n","    #     [[0,1,1,1,0], [1,1,1,1,1], [1,1,1,0,0], [1,1,1,1,0]]\n","    # ),\n","    # Dataset(\n","    #     [[0,1,0,1,0], [1,1,0,0,0], [1,0,1,0,0], [1,0,0,1,0]],\n","    #     [[0,1,0,1,0], [0,0,0,1,1], [0,0,1,0,1], [0,1,0,0,1]]\n","    # ),\n","    TranslateDataset(0, n=n), TranslateDataset(2, n=n), TranslateDataset(-2, n=n), TranslateDataset(1, n=n)\n","])\n","testing_set = D([\n","    TranslateDataset(-1, n=n), \n","    # Dataset(\n","    #     [[1,0,1,0,0], [0,0,0,1,1], [0,0,1,0,1], [0,1,0,1,0]],\n","    #     [[0,1,0,1,0], [1,0,0,0,1], [1,0,0,1,0], [0,0,1,0,1]]\n","    # ),\n","    ])\n","testing_set.batch_size = 1\n","# testing_set = None\n","\n","heads = 1\n","hidden_dim = 32\n","edge_dim = None\n","# edge_dim = 8\n","\n","n_inputs = training_set.n_inputs\n","n_outputs = training_set.n_outputs\n","height = 3\n","width = training_set.n_inputs\n","\n","cuda_device = torch.device(\"cuda:0\" if torch.cuda.is_available else \"cpu\")\n","# cuda_device = torch.device(\"cpu\")\n","\n","update_rule = UpdateRule(\n","    n_inputs, \n","    n_outputs,\n","    hidden_dim,\n","    edge_dim,\n","    network_width=hidden_dim,#hidden_dim,\n","    heads = heads,\n","    cuda_device=cuda_device\n",")\n","update_rule.build_graph(\n","    height,\n","    width,\n","    mode=\"dense\",\n","    input_mode=\"grid\",\n",")\n","\n","\n","update_rule = update_rule.to(cuda_device)\n","edge_attr = None\n","\n","update_rule.draw()\n","\n","#load initial_meta.pt\n","# update_rule.load_state_dict(torch.load(\"initial.pt\", map_location=cuda_device))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eaZnfyXSlAVh"},"outputs":[],"source":["from training import *\n","import time\n","n_steps = 6\n","batch_size = 15\n","training_set.batch_size = batch_size\n","lr = 0.001\n","optimizer = torch.optim.Adam(update_rule.parameters(), lr=lr)\n","use_wandb = True\n","\n","wandb_name = \"E11: Multi-head\"\n","if use_wandb:\n","    wandb.init(\n","        project=\"Experiments\",\n","        name=wandb_name,\n","        # resume=True,\n","        tags=[\"Translate Generalisation\"]\n","        )\n","    # wandb.run.log_code(\".\")\n","\n","start_time = time.time()\n","train_on_meta_set(\n","    update_rule, optimizer, training_set, testing_set, {\n","        \"n_steps\": n_steps,\n","        \"batch_size\": batch_size,\n","        \"n_epochs\": 30000000,\n","    }, edge_attr=edge_attr,# edge_index=best_edges,\n","    # wandb_loss = f\"baseline loss\",\n","    # wandb_acc = f\"baseline acc\",\n","    wandb_log = use_wandb,\n","    save_dir=None,#\"Edge_Weight\",\n","    last_idx = 3,\n","    device=cuda_device\n",")\n","# if use_wandb:\n","#     wandb.run.log_code(\".\")\n","#     wandb.finish()\n","\n","print(f\"Training took {time.time() - start_time} seconds\")\n","assert False, \"stop here\""]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#save update_rule\n","torch.save(update_rule.state_dict(), \"initial.pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gu5DhKWTlAVj"},"outputs":[],"source":["#load Edge_Weight.pt\n","with open(\"Edge_Weight.pt\", \"rb\") as f:\n","    update_rule.load_state_dict(torch.load(f))\n","\n","\n","x = update_rule.initial_state()\n","x, loss, network_output, correct, network_in = update_rule(\n","                    x, 1, DataLoader(TranslateDataset(0), shuffle=True), edge_attr=edge_attr\n","                )\n","print(loss, network_output, correct, network_in)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1666709143194,"user":{"displayName":"Liam Maclean","userId":"16471805810852624957"},"user_tz":240},"id":"1eDsf5dolAVj"},"outputs":[],"source":["import pygad\n","import pygad.torchga\n","from training import *\n","import torch\n","import time\n","import numpy as np\n","\n","\n","class EdgeModel(torch.nn.Module):\n","    def __init__(self) -> None:\n","        super().__init__()\n","\n","        self.edge_mask = nn.Parameter(torch.zeros(\n","            [update_rule.graph.edge_index.shape[1]]).byte(), requires_grad=False)\n","\n","    def get_edges(self):\n","        \"\"\"\n","        Returns elements of update_rule.edge_index coressponding to the incidces of edge_mask > 0\n","        \"\"\"\n","        # clamp edge mask to be between -1 and 1\n","        # self.edge_mask= nn.Parameter(self.edge_mask.clamp(-1, 1))\n","\n","        return update_rule.edge_index[:, self.edge_mask > 0]\n","\n","\n","def fitness_func(solution, sol_idx):\n","    global edge_model\n","    np.clip(solution, -1, 1)\n","    model_weights_dict = pygad.torchga.model_weights_as_dict(\n","        model=edge_model, weights_vector=solution)\n","    edge_model.load_state_dict(model_weights_dict)\n","\n","    update_rule = UpdateRule(\n","        n_inputs,\n","        n_outputs,\n","        hidden_dim,\n","        edge_dim,\n","        network_width=hidden_dim,\n","        heads=1\n","    )\n","\n","    update_rule.build_graph(\n","        height,\n","        width,\n","        mode=\"dense\"\n","    )\n","    optimizer = torch.optim.Adam(update_rule.parameters(), lr=0.001)\n","    loss_integral = train_on_meta_set(\n","        update_rule, optimizer, training_set, {\n","            \"n_steps\": 1,\n","            \"batch_size\": 5,\n","            \"n_epochs\": 40,\n","        }, edge_attr=edge_attr, verbose=False, edge_index=edge_model.get_edges(), wandb_log=False\n","    )\n","\n","    return -loss_integral.item()\n","\n","best_edge_index = []\n","\n","def callback_generation(ga_instance):\n","    global best_edge_index\n","    print(\"Generation = {}\".format(ga_instance.generations_completed))\n","\n","    if ga_instance.generations_completed % 10 == 0:\n","        best_sol = ga_instance.best_solution()\n","        print(\"Fitness    = {}\".format(best_sol[1]))\n","        print(best_sol[0])\n","        best_edge_index = update_rule.edge_index[:, best_sol[0]]\n","\n","        wandb.log({\n","            \"fitness\": best_sol[1],\n","        })\n","        with open(\"best_edge_index.txt\", \"w\") as f:\n","            f.write(str(best_edge_index[0].tolist()))\n","\n","\n","edge_model = EdgeModel()\n","\n","torch_ga = pygad.torchga.TorchGA(model=edge_model,\n","                                 num_solutions=10)\n","ga_instance = pygad.GA(num_generations=10000000,\n","                       num_parents_mating=5,\n","                       initial_population=torch_ga.population_weights,\n","                       fitness_func=fitness_func,\n","                       parent_selection_type=\"sss\",\n","                       crossover_type=\"single_point\",\n","                       mutation_type=\"random\",\n","                       mutation_percent_genes=10,\n","                       keep_parents=-1,\n","\n","                       # force binary weights\n","                       random_mutation_min_val=0,\n","                       random_mutation_max_val=2,\n","                       init_range_low=0,\n","                       init_range_high=2,\n","                       mutation_by_replacement=True,\n","                       gene_type=int,\n","                       #######\n","\n","                       on_generation=callback_generation)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wandb.init(project=\"neural-automata-evolve-on-meta-translate\",\n","           name=\"Evolve edges\",\n","           resume=True,\n","           )\n","wandb.run.log_code(\".\")\n","ga_instance.run()\n","wandb.finish()"]},{"cell_type":"markdown","metadata":{},"source":["ga_instance.save(filename=\"meta_edge_evo\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ga_instance.save(filename=\"meta_edge_evo\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qcVeRzR1lAVl"},"outputs":[],"source":["# best_binary = \"0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 1\".split(\" \")\n","# best_binary  = \"\"\"0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 1 0\n","#  0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n","#  0 1 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0\n","#  0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 0\n","#  1 0 1 0 0 0 0 1 1 1 1 0 0 1\"\"\".replace(\"\\n\", \"\").split(\" \")\n","\n","# best_binary = torch.tensor([int(x) for x in best_binary], dtype=torch.int)\n","\n","# iterate through update_rule.edge_index. if the element contains a value > 10, set the corresponding element in best_binary to 1\n","# for i, edge in enumerate(update_rule.edge_index.T):\n","# if edge[0] >= 10 or edge[1] >= 10:\n","#     best_binary[i] = 1\n","\n","#     if edge[0] < 10 and edge[1] < 10:\n","#         best_binary[i] = 1\n","\n","best_binary = update_rule.get_edge_weight().squeeze()  # .round()\n","best_edges = update_rule.edge_index[:, best_binary > 0.2]\n","\n","\n","n_nodes = height*width + n_inputs + n_outputs\n","nodes = torch.zeros(n_nodes, 1)\n","\n","color_map = [\"blue\"] * height*width + \\\n","    [\"green\"] * n_inputs + [\"red\"] * n_outputs\n","\n","# graph = Data(edge_index=best_edges, x=nodes)\n","graph = Data(edge_index=update_rule.edge_index, x=nodes, edge_attr=update_rule.get_edge_weight())\n","graph = utils.to_networkx(graph, to_undirected=False, remove_self_loops=False)\n","\n","# iterate over graph.edges and check if in best_edges.T\n","edge_color = []\n","edge_styles = []\n","edge_labels = {}\n","\n","for edge in graph.edges:\n","    if list(edge) not in list([list(x) for x in best_edges.T]):\n","        edge_color.append(\"blue\")\n","        edge_styles.append(\"dashed\")\n","    else:\n","        edge_color.append(\"red\")\n","        edge_styles.append(\"solid\")\n","\n","    edge_labels[edge] = str(edge)\n","\n","pos = nx.spring_layout(graph)\n","nx.draw(\n","    graph, pos, arrows=True, node_color=color_map, labels={i: i for i in range(n_nodes)}, edge_color=edge_color, style=edge_styles, arrowsize=13, font_color=\"whitesmoke\",\n","\n",")\n","\n","# nx.draw_networkx_edge_labels(\n","#     graph, pos,\n","#     edge_labels=edge_labels\n","# )\n","\n","plt.savefig(\"graph.png\", dpi=300)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["graph.edges(data=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Vgilro5lAVm"},"outputs":[],"source":["import torch\n","# best_edge_index = torch.tensor([[ 0,  0,  1,  1,  2,  2,  3,  3,  3,  4,  4,  4,  5,  5,  1,  2,  0,  1,\n","#           2,  6,  6,  7,  8,  8,  8,  5,  5,  3,  9,  9, 10, 10, 11, 11,  0,  1,\n","#           3,  7,  8,  9, 10, 11],\n","#         [ 1,  4,  3,  5,  1,  5,  0,  1,  4,  0,  2,  5,  1,  2,  6,  6,  7,  7,\n","#           8,  1,  2,  0,  0,  1,  2, 10, 11, 11,  4,  3,  5,  4,  5,  3,  0,  1,\n","#           3,  7,  8,  9, 10, 11]])\n","\n","best_binary = \"0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 1 1 0 0 0 0 1 0 1 0 1 1 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 1\".split(\" \")\n","\n","update_rule.edge_index[:, best_binary[0]]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pickle\n","\n","#pickle torch_ga\n","\n","with open(\"torch_ga.pickle\", \"wb\") as file:\n","    pickle.dump(torch_ga, file)\n","#Fitness    = -16.754362106323242\n","\n","best_binary  = \"\"\"0 1 0 0 1 0 0 1 0 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 1 0\n"," 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0\n"," 0 1 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1 0 0\n"," 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 0 0\n"," 1 0 1 0 0 0 0 1 1 1 1 0 0 1\"\"\".replace(\"\\n\", \"\").split(\" \")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RYK3caLPlAVm"},"outputs":[],"source":["update_rule.edge_index[:, 42:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U1tIa4xBlAVn"},"outputs":[],"source":["#normal distribution tensor\n","torch.randn(5, 1)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c8BBCcNilAVo"},"outputs":[],"source":["!conda env export --no-builds > environment.yml\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.randn([5,1])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch.nn.functional import one_hot\n","\n","one_hot(torch.arange(4), 6).unsqueeze(0).repeat(2,1,1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","b_size = 20\n","torch.concat((torch.zeros([b_size,7,32]), one_hot(torch.arange(7), 7).unsqueeze(0).repeat(b_size,1,1)), -1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import wandb\n","wandb.login()"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"8645a3289b338b219b448912b5fab165e90ac259118b71d23942463e3b992b2d"}}},"nbformat":4,"nbformat_minor":0}
